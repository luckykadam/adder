{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bits = 10\n",
    "n_samples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.randint(np.power(2, max_bits-1), size=(n_samples, 2))\n",
    "summed = np.sum(samples, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_binary_repr = [[np.binary_repr(a, width=max_bits), np.binary_repr(b, width=max_bits)] for a,b in samples]\n",
    "summed_binary_repr = [np.binary_repr(c, width=max_bits) for c in summed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_str = np.array([[list(a), list(b)] for a, b in samples_binary_repr])\n",
    "y_str = np.array([list(c) for c in summed_binary_repr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flipped = np.flip(x_str, axis=-1)\n",
    "y_flipped = np.flip(y_str, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.transpose((x_flipped == '1')*1, axes=(0, 2, 1))\n",
    "y = (y_flipped == '1')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, models\n",
    "\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullAdderCell(layers.Layer):\n",
    "    def __init__(self, hidden_units, **kwargs):\n",
    "        self.units = 1\n",
    "        self.state_size = 1\n",
    "        self.hidden_units = hidden_units\n",
    "        super(FullAdderCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel_1 = self.add_weight(shape=(input_shape[-1] + self.state_size, self.hidden_units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel_1')\n",
    "        self.bias_1 = self.add_weight(shape=(1, self.hidden_units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='bias_1')\n",
    "        self.kernel_2 = self.add_weight(shape=(self.hidden_units, self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel_2')\n",
    "        self.bias_2 = self.add_weight(shape=(1, self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='bias_2')\n",
    "        self.kernel_3 = self.add_weight(shape=(self.hidden_units, self.state_size),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel_3')\n",
    "        self.bias_3 = self.add_weight(shape=(1, self.state_size),\n",
    "                                      initializer='uniform',\n",
    "                                      name='bias_3')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        x = tf.concat([inputs, states[0]], axis=-1)\n",
    "        h = tf.keras.activations.tanh(tf.matmul(x, self.kernel_1) + self.bias_1)\n",
    "        output = tf.keras.activations.sigmoid(tf.matmul(h, self.kernel_2) + self.bias_2)\n",
    "        state = tf.keras.activations.sigmoid(tf.matmul(h, self.kernel_3) + self.bias_3)\n",
    "        return output, [state]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nrnn (RNN)                    (None, None, 1)           20        \n=================================================================\nTotal params: 20\nTrainable params: 20\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.RNN(FullAdderCell(3), return_sequences=True, input_shape=(None, 2)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 90000 samples\nEpoch 1/5\n78976/90000 [=========================>....] - ETA: 1s - loss: 0.6931 - accuracy: 0.5007"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5)\n",
    "scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(scores)"
   ]
  }
 ]
}