{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Adder using RNN in Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-67c8b658dcd2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-67c8b658dcd2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <a href=\"https://colab.research.google.com/github/luckykadam/adder/blob/master/rnn_full_adder.ipynb\">\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<a href=\"https://colab.research.google.com/github/luckykadam/adder/blob/master/rnn_full_adder.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
    "</a>\n",
    "<a href=\"https://github.com/luckykadam/adder/blob/master/rnn_full_adder.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for Google Colab compatibiity\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.0.0\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, activations\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bits = 8\n",
    "n_samples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.randint(np.power(2, max_bits-1), size=(n_samples, 2))\n",
    "summed = np.sum(samples, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_binary_repr = [[np.binary_repr(a, width=max_bits), np.binary_repr(b, width=max_bits)] for a,b in samples]\n",
    "summed_binary_repr = [np.binary_repr(c, width=max_bits) for c in summed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_str = np.array([[list(a), list(b)] for a, b in samples_binary_repr])\n",
    "y_str = np.array([list(c) for c in summed_binary_repr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flipped = np.flip(x_str, axis=-1)\n",
    "y_flipped = np.flip(y_str, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.transpose((x_flipped == '1')*1, axes=(0, 2, 1))\n",
    "y = (y_flipped == '1')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullAdderCell(layers.Layer):\n",
    "    def __init__(self, hidden_units, **kwargs):\n",
    "        self.units = 1\n",
    "        self.state_size = 1\n",
    "        self.hidden_units = hidden_units\n",
    "        super(FullAdderCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.hidden_weights = self.add_weight(shape=(input_shape[-1] + self.state_size, self.hidden_units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='hidden_weights')\n",
    "        self.hidden_bias = self.add_weight(shape=(1, self.hidden_units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='hidden_bias')\n",
    "        self.output_weights = self.add_weight(shape=(self.hidden_units, self.units + self.state_size),\n",
    "                                      initializer='uniform',\n",
    "                                      name='output_weights')\n",
    "        self.output_bias = self.add_weight(shape=(1, self.units + self.state_size),\n",
    "                                      initializer='uniform',\n",
    "                                      name='output_bias')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        x = tf.concat([inputs, states[0]], axis=-1)\n",
    "        h = tf.keras.activations.tanh(tf.matmul(x, self.hidden_weights) + self.hidden_bias)\n",
    "        o_s = tf.keras.activations.sigmoid(tf.matmul(h, self.output_weights) + self.output_bias)\n",
    "        output = o_s[:, :self.units]\n",
    "        state = o_s[:, self.units:]\n",
    "        return output, [state]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"full_adder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nrnn (RNN)                    (None, None, 1)           20        \n=================================================================\nTotal params: 20\nTrainable params: 20\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = tf.keras.Sequential(name='full_adder')\n",
    "model.add(layers.RNN(FullAdderCell(3), return_sequences=True, input_shape=(None, 2)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 90000 samples\nEpoch 1/5\n90000/90000 [==============================] - 10s 115us/sample - loss: 0.6916 - accuracy: 0.5087\nEpoch 2/5\n90000/90000 [==============================] - 9s 103us/sample - loss: 0.3403 - accuracy: 0.8986\nEpoch 3/5\n90000/90000 [==============================] - 9s 104us/sample - loss: 0.0644 - accuracy: 1.0000\nEpoch 4/5\n90000/90000 [==============================] - 9s 105us/sample - loss: 0.0131 - accuracy: 1.0000\nEpoch 5/5\n90000/90000 [==============================] - 9s 102us/sample - loss: 0.0034 - accuracy: 1.0000\n10000/1 - 1s - loss: 0.0017 - accuracy: 1.0000\n"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=5)\n",
    "scores = model.evaluate(x_test, y_test, verbose=2)"
   ]
  }
 ]
}